{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.helpers import get_standard_stats, get_res_df\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 14\n",
    "bounds = [(0,1),(1,2),(2,3),(3,4)]\n",
    "\n",
    "res_comp = pd.DataFrame()\n",
    "for seed in [42, 43, 44, 45, 46]:\n",
    "    path = 'data/results/traditional/mimic/microbiology_res_False/ab_False/seed_'+str(seed)+'/' \\\n",
    "                                'lookback_2/time_point(\\'random\\', 1)/sample_None_None/LGBMClassifier/'\n",
    "    df = pd.read_csv(path + 'test_gt_and_preds.csv') \n",
    "\n",
    "    time_differntiated = pd.DataFrame()\n",
    "\n",
    "    for t in bounds:\n",
    "        temp = df[(t[0]<=df['days_past']) & (df['days_past']<t[1])]\n",
    "        test_res = get_standard_stats(gt=temp['lot<5d'], preds=temp['pred'], preds_proba=temp['True'])\n",
    "        test_res.rename({'balanced_accuracy': 'Balanced Accuracy', 'prc_auc':'AUPRC', 'roc_auc':'AUROC', 'f1':'F1', 'recall':'Recall', 'precision':'Precision'}, inplace=True, axis=1)\n",
    "        test_res['days_past'] = '['+str(t[0])+','+str(t[1])+')'\n",
    "        time_differntiated = pd.concat([time_differntiated, test_res])\n",
    "    time_differntiated['seed'] = seed\n",
    "\n",
    "    res_comp = pd.concat([res_comp, time_differntiated])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "mean_std_data = res_comp.groupby(['days_past']).agg(['mean', 'std']).reset_index()\n",
    "display(mean_std_data)\n",
    "\n",
    "# Plot the values of GASAD_* columns with threshold on the x-axis\n",
    "\n",
    "\n",
    "# print([x[0] for x in mean_std_data.columns])\n",
    "# for col in ['Precision', 'Recall', 'F1', 'Balanced Accuracy', 'AUPRC', 'AUROC']:\n",
    "#     mean_col = mean_std_data[col]['mean']\n",
    "#     std_col = mean_std_data[col]['std']\n",
    "#     upper = mean_col + std_col\n",
    "#     lower = mean_col - std_col\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     sns.lineplot(x='days_past', y=mean_col, data=mean_std_data, label=col)\n",
    "#     plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "#     plt.xlabel('Days past')\n",
    "#     plt.ylabel(col)\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.legend()\n",
    "#     plt.legend(fontsize=fs)\n",
    "#     plt.xticks(fontsize=fs)\n",
    "#     plt.yticks(fontsize=fs)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_std_data = res_comp.groupby(['days_past']).agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Metriken fÃ¼r jeden Plot definieren\n",
    "metrics_1 = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n",
    "metrics_2 = ['F1', 'Precision', 'Recall']\n",
    "\n",
    "# Erster Plot (AUROC, AUPRC, Balanced Accuracy)\n",
    "plt.figure(figsize=(5, 5))\n",
    "for col in metrics_1:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.plot(mean_std_data['days_past'], mean_col, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Days past', fontsize=fs)\n",
    "plt.ylabel('Metric Value', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/experiments/time_dependence/'+'trad_basic_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# Zweiter Plot (F1, Precision, Recall)\n",
    "plt.figure(figsize=(5, 5))\n",
    "for col in metrics_2:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.plot(mean_std_data['days_past'], mean_col, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Days past', fontsize=fs)\n",
    "plt.ylabel('Metric Value', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/experiments/time_dependence/'+'trad_extended_metrics.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 14\n",
    "bounds = [(0,1),(1,2),(2,3),(3,4)]\n",
    "\n",
    "res_comp = pd.DataFrame()\n",
    "for seed in [42, 43, 44, 45, 46]:\n",
    "    path = 'data/results/traditional/mimic/microbiology_res_False/ab_False/seed_'+str(seed)+'/' \\\n",
    "                                'lookback_2/time_point(\\'random\\', 1)/sample_oversampling_None/LGBMClassifier/'\n",
    "    df = pd.read_csv(path + 'test_gt_and_preds.csv') \n",
    "\n",
    "    time_differntiated = pd.DataFrame()\n",
    "\n",
    "    for t in bounds:\n",
    "        temp = df[(t[0]<=df['days_past']) & (df['days_past']<t[1])]\n",
    "        test_res = get_standard_stats(gt=temp['lot<5d'], preds=temp['pred'], preds_proba=temp['True'])\n",
    "        test_res.rename({'balanced_accuracy': 'Balanced Accuracy', 'prc_auc':'AUPRC', 'roc_auc':'AUROC', 'f1':'F1', 'recall':'Recall', 'precision':'Precision'}, inplace=True, axis=1)\n",
    "        test_res['days_past'] = '['+str(t[0])+','+str(t[1])+')'\n",
    "        time_differntiated = pd.concat([time_differntiated, test_res])\n",
    "    time_differntiated['seed'] = seed\n",
    "\n",
    "    res_comp = pd.concat([res_comp, time_differntiated])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "mean_std_data = res_comp.groupby(['days_past']).agg(['mean', 'std']).reset_index()\n",
    "display(mean_std_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_data = res_comp.groupby(['days_past']).agg(['mean', 'std']).reset_index()\n",
    "\n",
    "\n",
    "metrics_1 = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n",
    "metrics_2 = ['F1', 'Precision', 'Recall']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for col in metrics_1:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.plot(mean_std_data['days_past'], mean_col, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Days past', fontsize=fs)\n",
    "plt.ylabel('Metric Value', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "#plt.savefig('images/experiments/time_dependence/'+'trad_basic_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for col in metrics_2:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.plot(mean_std_data['days_past'], mean_col, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Days past', fontsize=fs)\n",
    "plt.ylabel('Metric Value', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "#plt.savefig('images/experiments/time_dependence/'+'trad_extended_metrics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# res_comp = pd.DataFrame()\n",
    "# for seed in [42, 43, 44, 45, 46]:\n",
    "#     path = 'data/results/traditional/mimic/microbiology_res_False/ab_False/seed_'+str(seed)+'/' \\\n",
    "#                                 'lookback_2/time_point(\\'random\\', 1)/sample_None_None/LGBMClassifier/'\n",
    "#     test_gt_and_preds = pd.read_csv(traditional_res_path + 'test_gt_and_preds.csv') \n",
    "#     res_comp = pd.concat([res_comp, test_gt_and_preds])\n",
    "\n",
    "\n",
    "\n",
    "# display(res_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_dependence(seed):    \n",
    "    traditional_path = 'data/model_input/traditional/mimic/microbiology_res_False/ab_False/seed_'+str(seed)+'/'\n",
    "\n",
    "    traditional_res_path = 'data/results/traditional/mimic/microbiology_res_False/ab_False/seed_'+str(seed)+'/' \\\n",
    "                            'lookback_2/time_point(\\'random\\', 1)/sample_None_None/LGBMClassifier/'\n",
    "    \n",
    "    test_gt_and_preds = pd.read_csv(traditional_res_path + 'test_gt_and_preds.csv') \n",
    "\n",
    "    display(test_gt_and_preds)\n",
    "\n",
    "\n",
    "\n",
    "time_dependence(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bounds = [(0,1),(1,2),(2,3),(3,4)]\n",
    "\n",
    "res_comp = pd.DataFrame()\n",
    "for seed in [42, 43, 44, 45, 46]:\n",
    "    path = 'data/results/lstm/mimic/microbiology_res_False/ab_False/use_censored_True/lookback_7/aggregated_hours_4/seed_'+str(seed)+'/dropout_0-0/lambda_0-1/num_lin_layers_2/num_stacked_lstm_3/hidden_dim_256/lr_0-01/bs_128/is_tuned_False/use_relus_False/use_bn_False/'\n",
    "    df = pd.read_csv(path + 'test_gt_and_preds.csv') \n",
    "\n",
    "    time_differntiated = pd.DataFrame()\n",
    "    for t in bounds:\n",
    "        temp = df[(t[0]<=df['days_past']) & (df['days_past']<t[1])]\n",
    "        test_res = get_standard_stats(gt=temp['next_day'], preds=temp['pred'], preds_proba=temp['True'])\n",
    "        test_res.rename({'balanced_accuracy': 'Balanced Accuracy', 'prc_auc':'AUPRC', 'roc_auc':'AUROC', 'f1':'F1', 'recall':'Recall', 'precision':'Precision'}, inplace=True, axis=1)\n",
    "        test_res['days_past'] = '['+str(t[0])+','+str(t[1])+')'\n",
    "        time_differntiated = pd.concat([time_differntiated, test_res])\n",
    "    time_differntiated['seed'] = seed\n",
    "\n",
    "    res_comp = pd.concat([res_comp, time_differntiated])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "mean_std_data = res_comp.groupby(['days_past']).agg(['mean', 'std']).reset_index()\n",
    "display(mean_std_data)\n",
    "\n",
    "# Plot the values of GASAD_* columns with threshold on the x-axis\n",
    "\n",
    "\n",
    "print([x[0] for x in mean_std_data.columns])\n",
    "for col in ['Precision', 'Recall', 'F1', 'Balanced Accuracy', 'AUPRC', 'AUROC']:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.lineplot(x='days_past', y=mean_col, data=mean_std_data, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Days past')\n",
    "    plt.ylabel(col)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.legend(fontsize=fs)\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_data = res_comp.groupby(['days_past']).agg(['mean', 'std']).reset_index()\n",
    "\n",
    "metrics_1 = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n",
    "metrics_2 = ['F1', 'Precision', 'Recall']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for col in metrics_1:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.plot(mean_std_data['days_past'], mean_col, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Days past', fontsize=fs)\n",
    "plt.ylabel('Metric Value', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/experiments/time_dependence/'+'nd_basic_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for col in metrics_2:\n",
    "    mean_col = mean_std_data[col]['mean']\n",
    "    std_col = mean_std_data[col]['std']\n",
    "    upper = mean_col + std_col\n",
    "    lower = mean_col - std_col\n",
    "    plt.plot(mean_std_data['days_past'], mean_col, label=col)\n",
    "    plt.fill_between(mean_std_data['days_past'], lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Days past', fontsize=fs)\n",
    "plt.ylabel('Metric Value', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/experiments/time_dependence/'+'nd_extended_metrics.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
