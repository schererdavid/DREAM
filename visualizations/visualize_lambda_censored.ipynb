{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fs = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"data/model_input/lstm/mimic/microbiology_res_False/ab_False/lookback_7/aggregated_hours_4/seed_46/X_lstm_test.parquet\")\n",
    "\n",
    "\n",
    "display(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1', 'Balanced Accuracy', 'AUPRC', 'AUROC']\n",
    "results_df = pd.DataFrame()\n",
    "las = [0.0, 0.1,0.01,0.001,0.0001,0.00001, 0.2, 0.3, 0.4, 0.5]\n",
    "for seed in [42, 43, 44, 45, 46]:  \n",
    "    for la in las: \n",
    "        df = pd.read_csv(\"data/results/lstm/mimic/microbiology_res_False/ab_False/use_censored_True/lookback_7/aggregated_hours_4/seed_\"+str(seed)+\"/dropout_0-0/lambda_\"+str(la).replace(\".\",\"-\")+\"/num_lin_layers_2/num_stacked_lstm_3/hidden_dim_256/lr_0-01/bs_128/is_tuned_False/use_relus_False/use_bn_False/test_res.csv\")\n",
    "        df.rename({'balanced_accuracy': 'Balanced Accuracy', 'prc_auc':'AUPRC', 'roc_auc':'AUROC', 'f1':'F1', 'recall':'Recall', 'precision':'Precision'}, inplace=True, axis=1)\n",
    "        df['Lambda'] = la\n",
    "\n",
    "        results_df = pd.concat([results_df, df])\n",
    "\n",
    "mean_std_df = results_df.groupby('Lambda').agg({metric: ['mean', 'std'] for metric in metrics}).reset_index()\n",
    "#mean_std_df.to_csv(\"experiments/lamdas1.csv\")\n",
    "\n",
    "#[['Balanced Accuracy', 'AUPRC', 'AUROC']]\n",
    "\n",
    "display(mean_std_df)\n",
    "\n",
    "\n",
    "for_latex = mean_std_df.set_index(('Lambda', ''))\n",
    "for_latex.index.rename('Lambda', inplace=True)\n",
    "display(for_latex)\n",
    "print(for_latex[['Balanced Accuracy', 'AUPRC', 'AUROC']].to_latex(float_format=\"%.2f\", bold_rows=True, caption='Different Lambdas'))\n",
    "print(for_latex[['Precision', 'Recall', 'F1']].to_latex(float_format=\"%.2f\", bold_rows=True, caption='Different Lambdas'))\n",
    "\n",
    "\n",
    "\n",
    "def plot_metric(metric):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Lambda', y=(metric, 'mean'), data=mean_std_df, capsize=.1, color='skyblue')\n",
    "    plt.errorbar(x=np.arange(len(las)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='black', capsize=5)\n",
    "    #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "    plt.xlabel('Lambda', fontsize=fs)\n",
    "    plt.ylabel(metric, fontsize=fs)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/experiments/lambdas/'+'lambdas_'+metric+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for metric in metrics:\n",
    "    plot_metric(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# sns.set_theme()\n",
    "                     \n",
    "\n",
    "# metrics = ['precision', 'recall', 'f1', 'balanced_accuracy', 'prc_auc', 'roc_auc']\n",
    "# results_df = pd.DataFrame()\n",
    "\n",
    "# las = [0.0, 0.1,0.01,0.001,0.0001,0.00001, 0.2, 0.3, 0.4, 0.5]\n",
    "# for seed in [42, 43, 44, 45, 46]:  \n",
    "#     for la in las: \n",
    "#         df = pd.read_csv(\"data/results/lstm/mimic/microbiology_res_False/ab_False/use_censored_True/lookback_7/aggregated_hours_4/seed_\"+str(seed)+\"/dropout_0-0/lambda_\"+str(la).replace(\".\",\"-\")+\"/num_lin_layers_2/num_stacked_lstm_3/hidden_dim_256/lr_0-01/bs_128/is_tuned_False/use_relus_False/use_bn_False/test_res.csv\")\n",
    "\n",
    "#         df['lambda'] = la\n",
    "\n",
    "#         results_df = pd.concat([results_df, df])\n",
    "\n",
    "# mean_std_df = results_df.groupby('lambda').agg({metric: ['mean', 'std'] for metric in metrics}).reset_index()\n",
    "# #mean_std_df.to_csv(\"experiments/lamdas2.csv\")\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# for i, metric in enumerate(metrics, 1):\n",
    "#     plt.subplot(2, 3, i)\n",
    "#     sns.barplot(x='lambda', y=(metric, 'mean'), data=mean_std_df, capsize=.1)\n",
    "#     plt.errorbar(x=np.arange(len(las)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='red')\n",
    "#     #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "#     plt.xlabel('lambda')\n",
    "#     plt.ylabel(metric.capitalize())\n",
    "#     plt.ylim([0, 1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# display(mean_std_df)\n",
    "\n",
    "# def plot_metric(metric):\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     sns.barplot(x='lambda', y=(metric, 'mean'), data=mean_std_df, capsize=.1, color='skyblue')\n",
    "#     plt.errorbar(x=np.arange(len(las)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='black', capsize=5)\n",
    "#     #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "#     plt.xlabel('lambda')\n",
    "#     plt.ylabel(metric.capitalize())\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# for metric in metrics:\n",
    "#     plot_metric(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3rd lambda approach\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# sns.set_theme()\n",
    "                     \n",
    "\n",
    "# metrics = ['precision', 'recall', 'f1', 'balanced_accuracy', 'prc_auc', 'roc_auc']\n",
    "# results_df = pd.DataFrame()\n",
    "\n",
    "# las = [0.0, 0.1,0.01,0.001,0.0001,0.00001, 0.2, 0.3, 0.4, 0.5]\n",
    "# for seed in [42, 43, 44, 45, 46]:  \n",
    "#     for la in las: \n",
    "#         df = pd.read_csv(\"data/results/lstm/mimic/microbiology_res_False/ab_False/use_censored_True/lookback_7/aggregated_hours_4/seed_\"+str(seed)+\"/dropout_0-0/lambda_\"+str(la).replace(\".\",\"-\")+\"/num_lin_layers_2/num_stacked_lstm_3/hidden_dim_256/lr_0-01/bs_128/is_tuned_False/use_relus_False/use_bn_False/test_res.csv\")\n",
    "\n",
    "#         df['lambda'] = la\n",
    "\n",
    "#         results_df = pd.concat([results_df, df])\n",
    "\n",
    "# mean_std_df = results_df.groupby('lambda').agg({metric: ['mean', 'std'] for metric in metrics}).reset_index()\n",
    "# #mean_std_df.to_csv(\"experiments/lamdas3.csv\")\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# for i, metric in enumerate(metrics, 1):\n",
    "#     plt.subplot(2, 3, i)\n",
    "#     sns.barplot(x='lambda', y=(metric, 'mean'), data=mean_std_df, capsize=.1)\n",
    "#     plt.errorbar(x=np.arange(len(las)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='red')\n",
    "#     #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "#     plt.xlabel('lambda')\n",
    "#     plt.ylabel(metric.capitalize())\n",
    "#     plt.ylim([0, 1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# display(mean_std_df)\n",
    "\n",
    "# def plot_metric(metric):\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     sns.barplot(x='lambda', y=(metric, 'mean'), data=mean_std_df, capsize=.1, color='skyblue')\n",
    "#     plt.errorbar(x=np.arange(len(las)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='black', capsize=5)\n",
    "#     #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "#     plt.xlabel('lambda')\n",
    "#     plt.ylabel(metric.capitalize())\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# for metric in metrics:\n",
    "#     plot_metric(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme()\n",
    "                     \n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1', 'Balanced Accuracy', 'AUPRC', 'AUROC']\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "cens = [True, False]\n",
    "for seed in [42, 43, 44, 45, 46]:  \n",
    "    for c in cens: \n",
    "        df = pd.read_csv(\"data/results/lstm/mimic/microbiology_res_False/ab_False/use_censored_\"+str(c)+\"/lookback_7/aggregated_hours_4/seed_\"+str(seed)+\"/dropout_0-0/lambda_0-0/num_lin_layers_2/num_stacked_lstm_3/hidden_dim_256/lr_0-01/bs_128/is_tuned_False/use_relus_False/use_bn_False/test_res.csv\")\n",
    "        df.rename({'balanced_accuracy': 'Balanced Accuracy', 'prc_auc':'AUPRC', 'roc_auc':'AUROC', 'f1':'F1', 'recall':'Recall', 'precision':'Precision'}, inplace=True, axis=1)\n",
    "        df['Censored Included'] = c\n",
    "        \n",
    "        results_df = pd.concat([results_df, df])\n",
    "        \n",
    "\n",
    "mean_std_df = results_df.groupby('Censored Included').agg({metric: ['mean', 'std'] for metric in metrics}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "display(mean_std_df)\n",
    "\n",
    "for_latex = mean_std_df.set_index(('Censored Included', ''))\n",
    "for_latex.index.rename('Censored Included', inplace=True)\n",
    "display(for_latex)\n",
    "print(for_latex[['Balanced Accuracy', 'AUPRC', 'AUROC']].to_latex(float_format=\"%.2f\", bold_rows=True, caption='Model trained & tested on all vs. only uncensored'))\n",
    "\n",
    "display(for_latex.transpose())\n",
    "print(for_latex.transpose().to_latex(float_format=\"%.2f\", bold_rows=True, caption='Model trained & tested on all vs. only uncensored'))\n",
    "\n",
    "\n",
    "\n",
    "def plot_metric(metric):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.barplot(x='Censored Included', y=(metric, 'mean'), data=mean_std_df, capsize=.1, color='skyblue')\n",
    "    plt.errorbar(x=np.arange(len(cens)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='black', capsize=5)\n",
    "    #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "    plt.xlabel('Censored Included', fontsize=fs)\n",
    "    plt.ylabel(metric, fontsize=fs)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/experiments/censored/'+'censored_tested_all_'+metric+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for metric in metrics:\n",
    "    plot_metric(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "from utils.helpers import get_standard_stats                     \n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1', 'Balanced Accuracy', 'AUPRC', 'AUROC']\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "cens = [True, False]\n",
    "for seed in [42, 43, 44, 45, 46]:  \n",
    "    for c in cens: \n",
    "        df = pd.read_csv(\"data/results/lstm/mimic/microbiology_res_False/ab_False/use_censored_\"+str(c)+\"/lookback_7/aggregated_hours_4/seed_\"+str(seed)+\"/dropout_0-0/lambda_0-0/num_lin_layers_2/num_stacked_lstm_3/hidden_dim_256/lr_0-01/bs_128/is_tuned_False/use_relus_False/use_bn_False/test_gt_and_preds.csv\")\n",
    "        df = df[df['censored'] == False]\n",
    "        df = get_standard_stats(gt=df['next_day'], preds=df['pred'], preds_proba=df['True'])\n",
    "        df.rename({'balanced_accuracy': 'Balanced Accuracy', 'prc_auc':'AUPRC', 'roc_auc':'AUROC', 'f1':'F1', 'recall':'Recall', 'precision':'Precision'}, inplace=True, axis=1)\n",
    "\n",
    "        #display(df)\n",
    "        df['Censored Included'] = c\n",
    "\n",
    "        results_df = pd.concat([results_df, df])\n",
    "\n",
    "mean_std_df = results_df.groupby('Censored Included').agg({metric: ['mean', 'std'] for metric in metrics}).reset_index()\n",
    "\n",
    "for_latex = mean_std_df.set_index(('Censored Included', ''))\n",
    "for_latex.index.rename('Censored Included', inplace=True)\n",
    "display(for_latex.transpose())\n",
    "print(for_latex[['Balanced Accuracy', 'AUPRC', 'AUROC']].to_latex(float_format=\"%.2f\", bold_rows=True, caption='Model trained on all vs. only uncensored, tested only on uncensored'))\n",
    "\n",
    "print(for_latex.transpose().to_latex(float_format=\"%.2f\", bold_rows=True, caption='Model trained on all vs. only uncensored, tested only on uncensored'))\n",
    "display(mean_std_df)\n",
    "\n",
    "def plot_metric(metric):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.barplot(x='Censored Included', y=(metric, 'mean'), data=mean_std_df, capsize=.1, color='skyblue')\n",
    "    plt.errorbar(x=np.arange(len(cens)), y=mean_std_df[(metric, 'mean')], yerr=mean_std_df[(metric, 'std')], fmt='none', c='black', capsize=5)\n",
    "    #plt.title(f'Mean and SD of {metric.capitalize()}')\n",
    "    plt.xlabel('Censored Included', fontsize=fs)\n",
    "    plt.ylabel(metric, fontsize=fs)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/experiments/censored/'+'censored_tested_uncensored_'+metric+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for metric in metrics:\n",
    "    plot_metric(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
